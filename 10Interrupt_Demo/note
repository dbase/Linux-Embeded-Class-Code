     ================================================================================
中断和定时器:

1.中断:
	安来源分类
	安是否可以屏蔽分类
	安入口方法分类:   向量中断    
			 非向量中断: 多个中断共享一个入口地址, 由软件通过中断标志来识别具体的中断
	硬件定时器:
	
Linux中断处理程序结构:
1. 在Linux系统中中断处理程序分解为两个半部: 顶半部(Top Half) 底半部(Bottom Half)
  顶半部: 完成尽可能少的比较紧急的功能,往往只是简单的读取寄存器的中断状态,并且负责清除中断标志,
  	  然后再进行"登记中断" 的工作, 也就是将底半部处理程序挂在该设备的底半部执行队列中去,
	  该过程不可中断.  该过程屏蔽所有中断
  底半部: 它将完成中断事件的大部分任务, 该部分任务不是十分紧急,并且相对来说比较耗费时间,
   	  该部分可以被新的中断打断.

2. 中断申请和释放
   在内核源代码 kernel/irq/manage.c中实现
   1. 申请IRQ
      int request_irq(unsigned int irq, irq_handler_t handler,
		unsigned long irqflags, const char *devname, void *dev_id)

    request_irq - allocate an interrupt line
 *	@irq: Interrupt line to allocate  待申请的中断号
 *	@handler: Function to be called when the IRQ occurs
 *	@irqflags: Interrupt type flags
 *	@devname: An ascii name for the claiming device 中断设备的名称
 *	@dev_id: A cookie passed back to the handler function 传递给中断处理函数的指针, 通常用于共享中断时传递
 	设备结构体

	Flags:
 *
 *	IRQF_SHARED		Interrupt is shared 多个设备共享
 *	IRQF_DISABLED	Disable local interrupts while processing
 *	IRQF_SAMPLE_RANDOM	The interrupt can be used for entropy 用于随机数种子的随机采样
 *	IRQF_TRIGGER_*		Specify active edge(s) or level
 	IRQF_TRIGGER_RISING: 上升沿触发
	IRQF_TRIGGER_FAILING: 下降沿触发


中断处理函数： irq_handler_t
	       typedef void* (*irq_handler_t)(int irq, void* dev_id)
	
  2. 释放IRQ   
/**
 *	free_irq - free an interrupt
 *	@irq: Interrupt line to free
 *	@dev_id: Device identity to free
 *
 *	Remove an interrupt handler. The handler is removed and if the
 *	interrupt line is no longer in use by any driver it is disabled.
 *	On a shared IRQ the caller must ensure the interrupt is disabled
 *	on the card it drives before calling this function. The function
 *	does not return until any executing interrupts for this IRQ
 *	have completed.
 *
 *	This function must not be called from interrupt context.
 */
void free_irq(unsigned int irq, void *dev_id)

  3. 使能和屏蔽特定的中断
      kernerl/irq/manage.c 

/**
 *	disable_irq - disable an irq and wait for completion
 *	@irq: Interrupt to disable
 *
 *	Disable the selected interrupt line.  Enables and Disables are
 *	nested.
 *	This function waits for any pending IRQ handlers for this interrupt
 *	to complete before returning. If you use this function while
 *	holding a resource the IRQ handler may need you will deadlock.
 *
 *	This function may be called - with care - from IRQ context.
 */
void disable_irq(unsigned int irq)  屏蔽指定中断

/**
 *	disable_irq_nosync - disable an irq without waiting
 *	@irq: Interrupt to disable
 *
 *	Disable the selected interrupt line.  Disables and Enables are
 *	nested.
 *	Unlike disable_irq(), this function does not ensure existing
 *	instances of the IRQ handler have completed before returning.
 *
 *	This function may be called from IRQ context.
 */
void disable_irq_nosync(unsigned int irq)  屏蔽指定中断,但是他立即返回,不等待可能正在执行的中断处理程序

static void __enable_irq(struct irq_desc *desc, unsigned int irq) 开启指定中断

本CPU全部中断:
	local_irq_save()
	local_irq_restore()
	local_irq_enable()
	local_irq_disable()

  4. 底半部机制
     在Linux系统中实现底半部的机制主要有 tasklet, 工作队列, 软中断
     4.1 tasklet
       include/linux/interrupt.h
       #define DECLARE_TASKLET(name, func, data) \
          struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(0), func, data }

       #define DECLARE_TASKLET_DISABLED(name, func, data) \
          struct tasklet_struct name = { NULL, 0, ATOMIC_INIT(1), func, data }

       tasklet处理函数:
	void tasklet_func(unsigned long data);
       tasklet调用:
        void tasklet_schedule(struct tasklet_struct *taskletname)
  
    4.2 工作队列
       work queue 是Linux内核中将工作推后执行的一种机制. 这种机制和tasklet不同之处在于他是把推后的工作
       交由一个内核线程去执行, 因此工作队列的优势在于它允许重新调度甚至睡眠.
       4.2.1 work_struct 数据结构
          在2.6.0~2.6.19 中
	  		 struct work_struct{
			 	unsigned long pending;
				struct list_head entry;
				void (*func)(void *);
				void *data;
				void *wq_data;
				struct timer_list timer;
			 };
	 在2.6.20之后:
	 include/linux/workqueue.h 中定义
	  struct work_struct{
			 	atomic_long_t data;
				struct list_head entry;
				work_func_t func;
				...
			 };
	  typedef void (*work_funct_t)(struct work_struct *work);
	  
	  4.2.2 工作队列操作
	  DECLARE_WORK
	  DECLARE_DELAYED_WORK
	  INIT_WORK
	  INIT_DELAYED_WORK
	  schedule_work()
	  schedule_delayed_work()
	  create_workqueue()
	  queue_work()
	  queue_delayed_work()

    5. 软中断
       软中断使用软件方式来模拟硬件中断的概念
       tasklet就是基于软中断来实现的.


使用中断来控制按键：
	首先设置的是GPIO端口，然后申请中断号，request_irq() ,然后注册中断处理函数，使用tasklet
	来添加中断处理程序的底半部。


----------------------------------------
向量中断的入口点在 arch/arm/kernel/entry-armv.S   1182 行
	.globl	__vectors_start
__vectors_start:
	swi	SYS_ERROR0
	b	vector_und + stubs_offset
	ldr	pc, .LCvswi + stubs_offset
	b	vector_pabt + stubs_offset
	b	vector_dabt + stubs_offset
	b	vector_addrexcptn + stubs_offset
	b	vector_irq + stubs_offset
	b	vector_fiq + stubs_offset

	.globl	__vectors_end
__vectors_end:

非向量中断直接就是一个跳转，但是向量中断是跳转到另一个表的地方，然后再加上一个偏移量，
所以，向量中断有不同的中断入口


----------------------------------------
	   内核地址空间:
	      内核地址空间由内核负责映射,是固定的,不随进程改变.
   物理地址:  0-896MB: 称为"内存直接映射区".
	      896-1016MB: 896MB向上最大120MB 称为"动态映射区",是由内核动态分配使用的.
	      1016-1020: 4MB 称为"永久内存映射区",
	      1020-1024: 4MB 称为"固定映射区",其中最上面的4KB的地址用于隔离内核地址和其他程序,
	      	         称为 "4M隔离区."
	      
	      ---------
	      |-------|
	      |	      |
	      |-------|  用户应用程序
	      |-------|
	      |	      |
--------1024M-|-------|-------------------------0x40000000
	      |  4M   | 固定映射区(4M隔离区)  
	1020M |-------|-------------------------0x3fc00000
	      |	 4M   | 永久内存映射区
	1016M |-------|-------------------------0x3f800000
	      |	128M  | 动态映射区
	 896M |-------|-------------------------0x38000000
	      |	      |
	      |	      | 内存直接映射区
            0 ---------
	    
	    (逻辑内存分布图)	      

================================================================================

在有内核的情况下我们访问的都是虚拟地址，对于GPIO在系统中的虚拟地址映射为：
#define S3C64XX_PA_GPIO		(0x7F008000)
#define S3C64XX_VA_GPIO		S3C_ADDR(0x00500000)  //0x7f508000
#define S3C64XX_SZ_GPIO		SZ_4K
/arch/arm/mach-s3c6400/include/mach/map.h  定义了6410的内存映射范围	
	
由于ARM是统一编址的，所以不像x86一样，对于IO端口有自己的地址空间，称之为 IO端口；
在ARM 中对应的部分称之为 IO内存 。
内存与I/O :
	  1. IO端口操作
	   inb()
	   inw()
	   inl()
	   insb()
	   insw()
	   insl()
	  
	  IO内存操作：
	  arch/arm/include/asm/io.h 

读写IO内存：	
/*
 * Generic IO read/write.  These perform native-endian accesses.  Note
 * that some architectures will want to re-define __raw_{read,write}w.
 */
extern void __raw_writesb(void __iomem *addr, const void *data, int bytelen);
extern void __raw_writesw(void __iomem *addr, const void *data, int wordlen);
extern void __raw_writesl(void __iomem *addr, const void *data, int longlen);

extern void __raw_readsb(const void __iomem *addr, void *data, int bytelen);
extern void __raw_readsw(const void __iomem *addr, void *data, int wordlen);
extern void __raw_readsl(const void __iomem *addr, void *data, int longlen);

#define __raw_writeb(v,a)	(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a) = (v))
#define __raw_writew(v,a)	(__chk_io_ptr(a), *(volatile unsigned short __force *)(a) = (v))
#define __raw_writel(v,a)	(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a) = (v))

#define __raw_readb(a)		(__chk_io_ptr(a), *(volatile unsigned char __force  *)(a))
#define __raw_readw(a)		(__chk_io_ptr(a), *(volatile unsigned short __force *)(a))
#define __raw_readl(a)		(__chk_io_ptr(a), *(volatile unsigned int __force   *)(a))

/*
 * io{read,write}{8,16,32} macros
 */
#ifndef ioread8
#define ioread8(p)	({ unsigned int __v = __raw_readb(p); __v; })
#define ioread16(p)	({ unsigned int __v = le16_to_cpu((__force __le16)__raw_readw(p)); __v; })
#define ioread32(p)	({ unsigned int __v = le32_to_cpu((__force __le32)__raw_readl(p)); __v; })

#define iowrite8(v,p)	__raw_writeb(v, p)
#define iowrite16(v,p)	__raw_writew((__force __u16)cpu_to_le16(v), p)
#define iowrite32(v,p)	__raw_writel((__force __u32)cpu_to_le32(v), p)

#define ioread8_rep(p,d,c)	__raw_readsb(p,d,c)
#define ioread16_rep(p,d,c)	__raw_readsw(p,d,c)
#define ioread32_rep(p,d,c)	__raw_readsl(p,d,c)

#define iowrite8_rep(p,s,c)	__raw_writesb(p,s,c)
#define iowrite16_rep(p,s,c)	__raw_writesw(p,s,c)
#define iowrite32_rep(p,s,c)	__raw_writesl(p,s,c)

申请释放IO内存：
	include/linux/ioport.h

申请IO内存资源：
/* Convenience shorthand with allocation */
#define request_mem_region(start,n,name) __request_region(&iomem_resource, (start), (n), (name))
extern struct resource * __request_region(struct resource *,
					resource_size_t start,
					resource_size_t n, const char *name);
资源结构：
#include <linux/types.h>
/*
 * Resources are tree-like, allowing
 * nesting etc..
 */
struct resource {
	resource_size_t start;
	resource_size_t end;
	const char *name;
	unsigned long flags;
	struct resource *parent, *sibling, *child;
};

释放IO内存资源：
#define release_mem_region(start,n)	__release_region(&iomem_resource, (start), (n))
extern void __release_region(struct resource *, resource_size_t,
				resource_size_t);

IO内存映射操作：
   在内核中访问IO内存之前，需要首先使用ioremap()函数将设备所处的物理地址映射到内核虚拟地址，
   该地址可以用来存取特定的物理地址范围。通过ioremap()获得的虚拟地址，最后应该被 iounmap()释放掉。

   ioremap()函数类似于 vmalloc() 功能 ，vmalloc()是在物理地址超过968M更高的动态虚拟内存中进行分配；
   也需要建立新的页表，但是它并不进行vmalloc()中所执行的内存分配行为.
   arch/arm/include/asm/io.h

/*
 * ioremap and friends.
 *
 * ioremap takes a PCI memory address, as specified in
 * Documentation/IO-mapping.txt.
 *
 */
#ifndef __arch_ioremap
#define ioremap(cookie,size)		__arm_ioremap(cookie, size, MT_DEVICE)
#define ioremap_nocache(cookie,size)	__arm_ioremap(cookie, size, MT_DEVICE)
#define ioremap_cached(cookie,size)	__arm_ioremap(cookie, size, MT_DEVICE_CACHED)
#define ioremap_wc(cookie,size)		__arm_ioremap(cookie, size, MT_DEVICE_WC)
#define iounmap(cookie)			__iounmap(cookie)
#else
#define ioremap(cookie,size)		__arch_ioremap((cookie), (size), MT_DEVICE)
#define ioremap_nocache(cookie,size)	__arch_ioremap((cookie), (size), MT_DEVICE)
#define ioremap_cached(cookie,size)	__arch_ioremap((cookie), (size), MT_DEVICE_CACHED)
#define ioremap_wc(cookie,size)		__arch_ioremap((cookie), (size), MT_DEVICE_WC)
#define iounmap(cookie)			__arch_iounmap(cookie)
#endif

--------------------------------------------------------------------------------
ARM6410的物理地址分配：
	0X50000000－－－0X60000000    RAM 256M
	0x7f008000－－－0x7f008fff    GPIO Register   （又称IO内存）

测试程序：
unsigned char *kernelpagemem;
unsigned char *kernelkmalloc;
unsigned char *kernelvmalloc;

unsigned long addr;
void *addrp;
int order=0;

// get free page
kernelpagemem=(unsigned char *)__get_free_pages(GFP_KERNEL, order);  // virtual address
addr=virt_to_phys((void *)kernelpagemem);    // convert virtual address into physical address
addrp=phys_to_virt(addr);   // convert physical address into virtual address again

// get kmalloc
kernelkmalloc=(unsigned char *)kmalloc(100, GFP_KERNEL);
addr=virt_to_phys((void *)kernelkmalloc);    // convert virtual address into physical address
addrp=phys_to_virt(addr);   // convert physical address into virtual address again

// get vmalloc 
kernelvmalloc=(unsigned char *)vmalloc(1024*1024);
addr=virt_to_phys((void *)kernelvmalloc);    // convert virtual address into physical address
addrp=phys_to_virt(addr);   // convert physical address into virtual address again

// get GPIO kernel address
addr=virt_to_phys((void *)0xf4500000);  
addrp=phys_to_virt(addr);
(无法成功转换，因为它不是线性地址； 而上面的三种都可以成功转换，因为它们进行的都是线性地址转换)
// free all kernel memory
__free_pages((struct page *)kernelpagemem, order);
kfree(kernelkmalloc);
vfree(kernelvmalloc);

结果：
kernelpagemem =           0xcf5d3000 !
kernelpagemem phsy addr = 0x5f5d3000 !
kernelpagemem virt addr = 0xcf5d3000 !

kernelmalloc =            0xcf5b6780 !
kernelkmalloc phsy addr = 0x5f5b6780 !
kernelkmalloc virt addr = 0xcf5b6780 !

kernelvmalloc =           0xd2002000 !
kernelvmalloc phsy addr = 0x62002000 !
kernelvmalloc virt addr = 0xd2002000 !

GPIO phys addr = 0x84500000 !  错误不在范围之内0x7f008000－－－0x7f008fff    GPIO Register   （又称IO内存）
GPIO virt addr = 0xf4500000 !

由于GPIO的映射不是线性映射所以，不可以使用phys_to_virt 进行转化
--------------------------------------------------------------------------------

================================================================================

mmap 设备操作
     1. mmap系统调用
       1.在进程的虚拟内存空间查找一块VMA
       2.对这块VMA进行映射
       3.如果设备驱动程序或者文件系统的file_operations定义了mmap操作,则调用它
       4.将这个VMA插入到进程VMA链表中

     2. 虚拟内存区域
     	在Linux内核中使用 vm_area_struct 来描述虚拟内存区.
	include/linux/mm_types.h

/*
 * This struct defines a memory VMM memory area. There is one of these
 * per VM-area/task.  A VM area is any part of the process virtual memory
 * space that has a special rule for the page-fault handlers (ie a shared
 * library, the executable area etc).
 */
struct vm_area_struct {
	struct mm_struct * vm_mm;	/* The address space we belong to. */
	unsigned long vm_start;		/* Our start address within vm_mm. */
	unsigned long vm_end;		/* The first byte after our end address
					   within vm_mm. */

	/* linked list of VM areas per task, sorted by address */
	struct vm_area_struct *vm_next;

	pgprot_t vm_page_prot;		/* Access permissions of this VMA. */
	unsigned long vm_flags;		/* Flags, see mm.h. */

	struct rb_node vm_rb;

	/*
	 * For areas with an address space and backing store,
	 * linkage into the address_space->i_mmap prio tree, or
	 * linkage to the list of like vmas hanging off its node, or
	 * linkage of vma in the address_space->i_mmap_nonlinear list.
	 */
	union {
		struct {
			struct list_head list;
			void *parent;	/* aligns with prio_tree_node parent */
			struct vm_area_struct *head;
		} vm_set;

		struct raw_prio_tree_node prio_tree_node;
	} shared;

	/*
	 * A file's MAP_PRIVATE vma can be in both i_mmap tree and anon_vma
	 * list, after a COW of one of the file pages.	A MAP_SHARED vma
	 * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack
	 * or brk vma (with NULL file) can only be in an anon_vma list.
	 */
	struct list_head anon_vma_node;	/* Serialized by anon_vma->lock */
	struct anon_vma *anon_vma;	/* Serialized by page_table_lock */

	/* Function pointers to deal with this struct. */
	struct vm_operations_struct * vm_ops;

	/* Information about our backing store: */
	unsigned long vm_pgoff;		/* Offset (within vm_file) in PAGE_SIZE
					   units, *not* PAGE_CACHE_SIZE */
	struct file * vm_file;		/* File we map to (can be NULL). */
	void * vm_private_data;		/* was vm_pte (shared mem) */
	unsigned long vm_truncate_count;/* truncate_count or restart_addr */

#ifndef CONFIG_MMU
	atomic_t vm_usage;		/* refcount (VMAs shared if !MMU) */
#endif
#ifdef CONFIG_NUMA
	struct mempolicy *vm_policy;	/* NUMA policy for the VMA */
#endif
};

当我们的用户进行mmap()系统调用后,系统首先生成一个VMA, 然后在调用设备的mmap()操作, 内核不会调用VMA的open() 
函数, 通常需要在驱动的mmap()设备操作中显式调用 vma->vm_ops->opem() .  

    3. mmap设备操作
    将用户空间的一段地址关联到设备内存上. 当用户读写这段用户空间地址时, 实际上是在访问设备.
    int (*mmap)(struct file *filp, struct vm_area_struct *area);
    mmap操作的任务就是建立虚拟地址到物理地址的页表.

    大多数驱动都不需要提供设备内存到用户空间的映射能力, 因为, 对于串口等面向流的设备而言,实现这种映射毫无意义.
    mmap一般用于驱动要和应用程序进行大量数据传递的情况.
    
    4. mmap建立页表的方法
       4.1 使用 remap_pfn_range()函数一次建立所有页表, 在任何地址空间中使用
       int remap_pfn_range(struct vm_area_struct *vma, unsigned long addr, unsigned long pfn, unsigned 
pgprot_t prot);
	 mm/memory.c
	 vma: 虚拟内存区域指针
	 addr: 虚拟内存起始地址
	 pfn:要映射的物理地址所在的物理页侦号,可通过将物理地址>>PAGE_SHIFT得到
	 prot: vma的保护属性

       4.2 使用nopage()每次为vma建立一个也表, 推荐在RAM空间中使用
       

   5. I/O 内存静态映射
   在ARM linux系统中, 通常会在内核代码中建立外设I/O内存物理地址到内核虚拟地址的静态映射,这个映射
   通过map_desc()数据结构来描述.
   arch/arm/include/asm/mach/map.h 
   
struct map_desc {
	unsigned long virtual;
	unsigned long pfn;
	unsigned long length;
	unsigned int type;
};

   6. DMA
    arch/arm/kernel/dma.c中实现
/*
 * Request DMA channel
 *
 * On certain platforms, we have to allocate an interrupt as well...
 */
int request_dma(dmach_t channel, const char *device_id)
void free_dma(dmach_t channel)

     7. MISC设备 混杂设备
     它是Linux中的一类特殊设备,它们共享一个主设备号(10), 但是次设备号不同.
     
     include/linux/miscdevice.h

struct miscdevice  {
	int minor;
	const char *name;
	const struct file_operations *fops;
	struct list_head list;
	struct device *parent;
	struct device *this_device;
};

driver/char/misc.c

extern int misc_register(struct miscdevice * misc);
extern int misc_deregister(struct miscdevice *misc);
